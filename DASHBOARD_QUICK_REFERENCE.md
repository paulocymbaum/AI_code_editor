# Quick Reference: Dashboard Creation

## ðŸš€ Quick Start

```bash
# 1. Make sure API key is set
export GROQ_API_KEY='your-key-here'

# OR use .env file
echo "GROQ_API_KEY=your-key-here" > .env

# 2. Run simple test
python3 examples/create_dashboard_with_agent.py --test

# 3. Run full dashboard creation
python3 examples/create_dashboard_with_agent.py
```

---

## ðŸ“Š What Gets Generated

The agent creates a complete dashboard with:

```
demo/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â””â”€â”€ dashboard/
â”‚   â”‚       â””â”€â”€ page.tsx           # Main dashboard page
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ Sidebar.tsx            # Collapsible sidebar with animations
â”‚   â”‚   â”œâ”€â”€ TabNavigation.tsx      # Tab bar with 4 tabs
â”‚   â”‚   â”œâ”€â”€ Header.tsx             # Dashboard header
â”‚   â”‚   â”œâ”€â”€ Footer.tsx             # Dashboard footer
â”‚   â”‚   â””â”€â”€ StatCard.tsx           # Metric cards
â”‚   â””â”€â”€ store/
â”‚       â”œâ”€â”€ store.ts               # Redux store configuration
â”‚       â”œâ”€â”€ hooks.ts               # Typed Redux hooks
â”‚       â”œâ”€â”€ sidebarSlice.ts        # Sidebar state slice
â”‚       â”œâ”€â”€ tabnavigationSlice.ts  # Tab state slice
â”‚       â””â”€â”€ ...                    # Other slices
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ next.config.js
â””â”€â”€ postcss.config.js
```

---

## ðŸ” Monitoring Progress

### Real-time Monitoring
```bash
# Watch the log file as it's created
tail -f dashboard_run.log

# Or run with tee to see output and save to file
python3 examples/create_dashboard_with_agent.py 2>&1 | tee dashboard_run.log
```

### Check Status
```bash
# View iteration progress
grep "ITERATION" dashboard_run.log

# See which tools were executed
grep "Using Tool:" dashboard_run.log

# Check for errors
grep "ERROR\|FAILED" dashboard_run.log

# See successful completions
grep "SUCCESS" dashboard_run.log
```

---

## ðŸ“ˆ Understanding the Output

### Console Output Format

```
================================================================================
ITERATION 1/15
================================================================================

ðŸ¤” Deciding next action...
ðŸ“Œ Action Type: tool_use

ðŸ”§ Using Tool: generate_page_with_components
ðŸ’¬ Message: Generating dashboard with components
ðŸ“ Parameters: {
  "page_name": "dashboard",
  "page_path": "./demo/src/app/dashboard/page.tsx",
  "components": [...]
}
âš™ï¸  Executing...
âœ… SUCCESS!
ðŸ“¦ Data: {...}
```

**Key Indicators:**
- ðŸ¤” = AI is thinking/deciding
- ðŸ”§ = Tool is being executed
- âœ… = Success
- âŒ = Failure/Error
- ðŸ“¦ = Result data

---

## ðŸ› Troubleshooting

### Problem: "Tool not found: generate_redux_store"
**Solution:** This was fixed! The tool is now correctly named `generate_redux_setup`.

### Problem: "API key not found"
**Solution:** 
```bash
# Set the API key
export GROQ_API_KEY='your-key-here'

# Or create .env file
echo "GROQ_API_KEY=your-key-here" > .env

# Verify it's set
echo $GROQ_API_KEY
```

### Problem: "429 Too Many Requests"
**Solution:** Groq API rate limit reached. The agent will automatically retry after waiting. You can:
- Wait for the retry
- Use a lower rate of requests
- Upgrade your Groq API plan

### Problem: Agent keeps repeating same action
**Solution:** This is an LLM behavior. The agent should move forward after 2-3 iterations. Check if:
- The tool is actually succeeding
- The files are being created
- There are no errors in the logs

### Problem: No files generated
**Solution:** Check:
```bash
# Verify demo directory exists
ls -la demo/

# Check if files were created
find demo/ -type f -name "*.tsx" -o -name "*.ts"

# Look for errors in the log
grep "ERROR" dashboard_run.log
```

---

## ðŸ§ª Testing

### Minimal Test
```bash
python3 examples/create_dashboard_with_agent.py --test
```
Expected output: Single button component created in ~10 seconds

### Full Test
```bash
python3 examples/create_dashboard_with_agent.py
```
Expected output: Complete dashboard with 10+ files in ~2-3 minutes

---

## ðŸ“Š Performance Metrics

| Metric | Test Mode | Full Dashboard |
|--------|-----------|----------------|
| Execution Time | ~10-15s | ~60-120s |
| API Calls | ~3-5 | ~15-25 |
| Files Generated | 1 | 10-15 |
| Iterations | 1-3 | 5-10 |

---

## ðŸ”§ Configuration

### Adjusting Max Iterations
```python
# In create_dashboard_with_agent.py
result = await agent.execute(user_request, max_iterations=15)  # Increase if needed
```

### Changing Model
```python
# In create_dashboard_with_agent.py
agent = AICodeAgent(groq_api_key=api_key, model="llama-3.1-70b-versatile")
```

### Enable Debug Logging
```python
# At the top of the script
logging.basicConfig(
    level=logging.DEBUG,  # Change to DEBUG
    format='%(asctime)s [%(levelname)s] %(message)s'
)
```

---

## ðŸ“ Execution Report

After completion, check the JSON report:

```bash
cat dashboard_creation_report.json | python3 -m json.tool
```

Report contents:
```json
{
  "success": true,
  "iterations": 5,
  "tool_results": [...],
  "errors": [],
  "response": "Summary of what was created",
  "metadata": {
    "execution_time_seconds": 45.67,
    "timestamp": "2025-12-09T14:11:45.123456",
    "files_generated": 12,
    "total_size_bytes": 34567
  }
}
```

---

## ðŸŽ¯ Expected Features

The generated dashboard includes:

### âœ… Sidebar Menu
- Collapsible/expandable
- Smooth CSS transitions
- Active menu item highlighting
- Icons with hover effects
- Responsive (auto-collapse on mobile)
- Menu items: Dashboard, Analytics, Reports, Settings, Profile

### âœ… Tab Navigation
- 4 tabs: Overview, Analytics, Data, Settings
- Active tab indicator
- Smooth transitions
- Redux-connected state

### âœ… Redux State Management
- Centralized store
- Slices for UI state (sidebar, tabs)
- Slices for component data
- Typed hooks (useAppSelector, useAppDispatch)
- Mock data generation

### âœ… Professional UX
- Tailwind CSS styling
- TypeScript type safety
- Responsive design
- Accessibility features
- Modern React patterns

---

## ðŸ’¡ Tips

1. **Run test first** to verify everything works
2. **Monitor the logs** to catch issues early
3. **Check generated files** after each run
4. **Save logs** for debugging: `2>&1 | tee dashboard_run.log`
5. **Review the report** to understand what was created

---

**For detailed debugging info, see:** `DASHBOARD_DEBUG_IMPROVEMENTS.md`
